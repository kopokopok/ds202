{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_2_DS_UA_202",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python [conda env:rds_env]",
      "language": "python",
      "name": "conda-env-rds_env-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu8QNsWRb_xp"
      },
      "source": [
        "# Detecting and Mitigating Age Bias on Credit Decisions \n",
        "\n",
        "The goal of this tutorial is to introduce the basic functionality of [AI Fairness 360](https://aif360.mybluemix.net), an open source toolkit developed by IBM for bias mitigation. \n",
        "\n",
        "### Biases and Machine Learning\n",
        "\n",
        "A machine learning model predicts an outcome for a particular instance. For example, given an instance of a loan application, we may use a model to predict whether the applicant will repay the loan. The model makes predictions based on a training dataset, where many other instances (other loan applications) and observed outcomes (whether a loan was repaid) are provided. A machine learning algorithm will attempt to find patterns, or generalizations, in the training dataset to use when a prediction for a new instance is needed. For example, the model may discover a pattern whereby a person with a salary over \\$40,000 and  outstanding debt of less than \\$5 is very likely to repay a loan. In many domains this technique, called supervised machine learning, has worked very well.\n",
        "\n",
        "However, a machine learning model may make predictions that, if used to make decisions, would be undesirable or even illegal. For example, a loan repayment model may determine that age plays a significant role in the prediction of repayment because the training dataset happened to have better repayment for one age group compared to another. This raises two problems: 1) the training dataset may not be representative of the true population of loan applications for all age groups, and 2) even if it is representative, it is illegal (with limited exceptions) to base loan decisions on an applicant's age, regardless of whether this improves the accuracy of predictions based on historical data.\n",
        "\n",
        "AI Fairness 360 is a toolkit designed to help address this problem with _fairness metrics_ and _bias mitigators_.  Fairness metrics can be used to check for bias in machine learning workflows.  Bias mitigators can be used to overcome bias in the workflow to produce a more fair outcome. \n",
        "\n",
        "A bias detection and mitigation strategy needs to be tailored to the particular bias of interest.  More specifically, we need to define the attribute(s), called _protected attributes_, of interest.\n",
        "\n",
        "### The Machine Learning Workflow\n",
        "\n",
        "To understand how bias can enter a machine learning model, we first review the basics of how a model is created in a supervised machine learning process.  \n",
        "\n",
        "![machine learning pipeline](https://drive.google.com/uc?export=view&id=1a2f6vuCpjGwG6dNMeHUZKqLlQioRL02S)\n",
        "\n",
        "The original data contains instances, where each instance has two components: an outcome and a set of features. For example, the outcome may be whether or not a loan was repaid, and the features may be the income, age, and gender of the applicant. First, we split the original data into _training data_ and _test data_. Second, we train a machine learning algorithm on this training data to produce a machine learning model. Third, we use the trained model to make predicts for new instances, e.g. we can predict the probability of repayment for new loan applications. We typically assess the accuracy of the model on the test dataset.\n",
        "\n",
        "Typically, this test dataset has the same format as the training dataset and often these two datasets derive from the same initial dataset. For example, a random partitioning algorithm may be used to split the initial dataset into training and test data subsets.\n",
        "\n",
        "Bias can enter the system in any of the three steps above. The training data set may be biased if a particular outcome is overrepresented for some types of instances. The algorithm may be biased if it assigns importance to particular features in the input that we believe should not be used or if the model produces predictions that are systematically less favorable to instances with particular features. The test data set may be biased if it has observed outcomes that are unrepresentative of the broader population of instances. These examples are not exhaustive; bias can enter the machine learning process in several other ways.\n",
        "\n",
        "These three points in the machine learning process represent stages for testing and mitigating bias. In the AI Fairness 360 codebase, we call these stages _pre-processing_, _in-processing_, and _post-processing_. Typically, we can intervene to identify or mitigate bias at any of these three stages.\n",
        "\n",
        "### AI Fairness 360\n",
        "\n",
        "We are now ready to utilize AI Fairness 360 (`aif360`) to detect and mitigate bias. We will use the German Credit dataset, splitting the data into a training and test dataset.  We will look for bias in the creation of a machine learning model that predicts whether an applicant should be given credit based on various features from a typical credit application. The protected attribute will be \"Age\", with \"1\" (older than or equal to 25) and \"0\" (younger than 25) being the values for the _privileged_ and _unprivileged_ groups, respectively.\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Install and import packages and modules\n",
        "2. Set bias detection options, load dataset, and split the data into training data and test data\n",
        "3. Compute fairness metric on the original training dataset\n",
        "5. Mitigate bias using an in-processing algorithm, called adversarial debiasing, and compute the fairness metrics under this model\n",
        "\n",
        "At the end of the notebook, there are optional exercises to mitigate bias using a pre-processing algorithm and another algorithm of your choosing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSvZzh_-ntSU"
      },
      "source": [
        "\n",
        "# Import Statements\n",
        "\n",
        "First, we install the necessary packages. Then we import several components from the `aif360` package. We also import the GermanDataset, metrics to check for bias, and classes related to the algorithm we will use to mitigate bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_4p0U7o1lnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82818fed-2d5e-4a9f-8662-8ec4f55f52db"
      },
      "source": [
        "%pip install numpy matplotlib seaborn\n",
        "!pip install numba==0.48\n",
        "!pip install aif360==0.2.2\n",
        "!python -m pip install BlackBoxAuditing\n",
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: numba==0.48 in /usr/local/lib/python3.7/dist-packages (0.48.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.48) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba==0.48) (0.31.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from numba==0.48) (1.19.5)\n",
            "Requirement already satisfied: aif360==0.2.2 in /usr/local/lib/python3.7/dist-packages (0.2.2)\n",
            "Requirement already satisfied: pandas>=0.23.3 in /usr/local/lib/python3.7/dist-packages (from aif360==0.2.2) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from aif360==0.2.2) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from aif360==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.3->aif360==0.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.3->aif360==0.2.2) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.3->aif360==0.2.2) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->aif360==0.2.2) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->aif360==0.2.2) (3.1.0)\n",
            "Requirement already satisfied: BlackBoxAuditing in /usr/local/lib/python3.7/dist-packages (0.1.54)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.19.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (2.6.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->BlackBoxAuditing) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->BlackBoxAuditing) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->BlackBoxAuditing) (2018.9)\n",
            "Requirement already satisfied: tensorflow==1.13.1 in /usr/local/lib/python3.7/dist-packages (1.13.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.43.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJxDwiuVb_xt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d0ab65-4b79-4fac-e527-2b7647e061b9"
      },
      "source": [
        "# import all necessary packages\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "from aif360.datasets import GermanDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, DatasetMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
        "from aif360.explainers import MetricTextExplainer, MetricJSONExplainer\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import json\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQj5VqOSb_xt"
      },
      "source": [
        "# Load Data, Specify Protected Attribute, and Split Data\n",
        "\n",
        "Next we'll load the German Credit Risk data and set the protected attribute to be age. We then split the original dataset into training and test data subsets. Although we'll only use the training dataset in this tutorial, a normal workflow would also use a test dataset for assessing the efficacy (accuracy, fairness, etc) during the development of a machine learning model. Finally, we create two variables to represent the privileged and unprivileged values for the age attribute.\n",
        "\n",
        "The German Credit Risk data contains 1000 entries with 20 categorical and integer attributes prepared. In this dataset, each entry represents a person applying for a loan. Each person is classified as a \"good\" or \"bad\" credit risk. The original dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29).\n",
        "\n",
        "Recall that a _protected attribute_ is the attribute of interest, i.e. the attribute for which you want to test bias. The _privileged class_ is a subset of protected attribute values which we define as privileged from a fairness perspective. In the German dataset, older applicants (age >= 25) are the privileged class and younger applicants (age < 25) are the unprivileged class. We therefore have binary membership in a protected group (age) and a binary classification problem (good or bad credit risk).\n",
        "\n",
        "Let's prepare the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYB3PkStb_xv"
      },
      "source": [
        "# note that we drop sex, which may also be a protected attribute\n",
        "data_original = GermanDataset(protected_attribute_names=['age'],\n",
        "                              privileged_classes=[lambda x: x >= 25],\n",
        "                              features_to_drop=['personal_status', 'sex'])\n",
        "\n",
        "data_train, data_test = data_original.split([0.7], shuffle=True)\n",
        "\n",
        "privileged_groups = [{'age': 1}]\n",
        "unprivileged_groups = [{'age': 0}]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsFiFKReb_xw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5e5204-923b-48af-e9dc-2e49e36436ae"
      },
      "source": [
        "print(\"Original one hot encoded german dataset shape: \",data_original.features.shape)\n",
        "print(\"Train dataset shape: \", data_train.features.shape)\n",
        "print(\"Test dataset shape: \", data_test.features.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original one hot encoded german dataset shape:  (1000, 57)\n",
            "Train dataset shape:  (700, 57)\n",
            "Test dataset shape:  (300, 57)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTTLfl2tb_xw"
      },
      "source": [
        "The object ```dataset_orig``` is an aif360 dataset, which has some useful methods and attributes that you can explore. More documentation is available at https://aif360.readthedocs.io/en/latest/modules/datasets.html.\n",
        "\n",
        "For now, we'll just transform the data into a pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Aonmt3b_xw"
      },
      "source": [
        "df, dict_df = data_original.convert_to_dataframe()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jax9cvjub_xx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "162ab6e2-9d77-49c1-d322-e22560c05e1b"
      },
      "source": [
        "print(\"Shape: \", df.shape)\n",
        "df.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape:  (1000, 58)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1f5c3e61-b089-4bba-b8b3-65098696e1e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>investment_as_income_percentage</th>\n",
              "      <th>residence_since</th>\n",
              "      <th>age</th>\n",
              "      <th>number_of_credits</th>\n",
              "      <th>people_liable_for</th>\n",
              "      <th>status=A11</th>\n",
              "      <th>status=A12</th>\n",
              "      <th>status=A13</th>\n",
              "      <th>status=A14</th>\n",
              "      <th>credit_history=A30</th>\n",
              "      <th>credit_history=A31</th>\n",
              "      <th>credit_history=A32</th>\n",
              "      <th>credit_history=A33</th>\n",
              "      <th>credit_history=A34</th>\n",
              "      <th>purpose=A40</th>\n",
              "      <th>purpose=A41</th>\n",
              "      <th>purpose=A410</th>\n",
              "      <th>purpose=A42</th>\n",
              "      <th>purpose=A43</th>\n",
              "      <th>purpose=A44</th>\n",
              "      <th>purpose=A45</th>\n",
              "      <th>purpose=A46</th>\n",
              "      <th>purpose=A48</th>\n",
              "      <th>purpose=A49</th>\n",
              "      <th>savings=A61</th>\n",
              "      <th>savings=A62</th>\n",
              "      <th>savings=A63</th>\n",
              "      <th>savings=A64</th>\n",
              "      <th>savings=A65</th>\n",
              "      <th>employment=A71</th>\n",
              "      <th>employment=A72</th>\n",
              "      <th>employment=A73</th>\n",
              "      <th>employment=A74</th>\n",
              "      <th>employment=A75</th>\n",
              "      <th>other_debtors=A101</th>\n",
              "      <th>other_debtors=A102</th>\n",
              "      <th>other_debtors=A103</th>\n",
              "      <th>property=A121</th>\n",
              "      <th>property=A122</th>\n",
              "      <th>property=A123</th>\n",
              "      <th>property=A124</th>\n",
              "      <th>installment_plans=A141</th>\n",
              "      <th>installment_plans=A142</th>\n",
              "      <th>installment_plans=A143</th>\n",
              "      <th>housing=A151</th>\n",
              "      <th>housing=A152</th>\n",
              "      <th>housing=A153</th>\n",
              "      <th>skill_level=A171</th>\n",
              "      <th>skill_level=A172</th>\n",
              "      <th>skill_level=A173</th>\n",
              "      <th>skill_level=A174</th>\n",
              "      <th>telephone=A191</th>\n",
              "      <th>telephone=A192</th>\n",
              "      <th>foreign_worker=A201</th>\n",
              "      <th>foreign_worker=A202</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>1169.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48.0</td>\n",
              "      <td>5951.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12.0</td>\n",
              "      <td>2096.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42.0</td>\n",
              "      <td>7882.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24.0</td>\n",
              "      <td>4870.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f5c3e61-b089-4bba-b8b3-65098696e1e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f5c3e61-b089-4bba-b8b3-65098696e1e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f5c3e61-b089-4bba-b8b3-65098696e1e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   month  credit_amount  ...  foreign_worker=A202  credit\n",
              "0    6.0         1169.0  ...                  0.0     1.0\n",
              "1   48.0         5951.0  ...                  0.0     2.0\n",
              "2   12.0         2096.0  ...                  0.0     1.0\n",
              "3   42.0         7882.0  ...                  0.0     1.0\n",
              "4   24.0         4870.0  ...                  0.0     2.0\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEeX43jZb_xy"
      },
      "source": [
        "Let's take a look at our primary feature of interest, _age_, and the outcome, _credit_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdG0eNdyb_xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "d24d09ec-c4b6-4872-96ad-e9b5d8787761"
      },
      "source": [
        "print(\"Key: \", data_original.metadata['protected_attribute_maps'][1])\n",
        "df['age'].value_counts().plot(kind='bar')\n",
        "plt.xlabel(\"Age (0 = under 25, 1 = over 25)\")\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key:  {1.0: 'Old', 0.0: 'Young'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEMCAYAAAArnKpYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZc0lEQVR4nO3df/RldV3v8eeLX4JY8muaphloKCe8lIk4EoaWQpagOZRKsLwxcWc1dcPKH92kn+Tqti52S5LulZxCHSxFxIgpSaPxR9ldgAMSCEhMCDHjwEzIjxSV0Pf943y+ew7f+c53zgyzzxnm+3ysddbZ+7M/e5/3OQzf1/69U1VIkgSwz6QLkCTtOQwFSVLHUJAkdQwFSVLHUJAkdfabdAFPxhFHHFGLFy+edBmS9JRyww03/HtVzZtp2lM6FBYvXsy6desmXYYkPaUkuWd709x9JEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqPKWvaH6qWHzeRyZdwl7l7gteMekSpL2WWwqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnq9BoKSd6Y5NYkn0vygSQHJjk6yXVJ1if5YJIDWt+ntfH1bfriPmuTJG2rt1BIshD4JWBpVX0fsC9wJvA24MKqehbwILCizbICeLC1X9j6SZLGqO/dR/sBByXZD3g6sAk4GbiiTV8NnN6Gl7Vx2vRTkqTn+iRJQ3oLharaCPwB8G8MwuBh4Abgoap6vHXbACxswwuBe9u8j7f+h09fbpKVSdYlWbdly5a+ypekOanP3UeHMlj7Pxr4DuBg4OVPdrlVtaqqllbV0nnz5j3ZxUmShvS5++hHgC9U1Zaq+k/gL4GTgEPa7iSARcDGNrwROBKgTX8m8ECP9UmSpukzFP4NODHJ09uxgVOA24BPAK9pfZYDV7XhNW2cNv3jVVU91idJmqbPYwrXMThgfCNwS/usVcBbgDclWc/gmMElbZZLgMNb+5uA8/qqTZI0s14fslNV5wPnT2u+Czhhhr5fA17bZz2SpNl5RbMkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqdPnM5qPSXLT0OuRJG9IcliSa5Lc2d4Pbf2T5KIk65PcnOT4vmqTJM2szyev3VFVx1XVccDzgUeBKxk8UW1tVS0B1rL1CWunAkvaayVwcV+1SZJmNq7dR6cA/1pV9wDLgNWtfTVwehteBlxaA9cChyRZMKb6JEmMLxTOBD7QhudX1aY2fB8wvw0vBO4dmmdDa5MkjUnvoZDkAOBVwIemT6uqAmonl7cyybok67Zs2bKbqpQkwXi2FE4Fbqyq+9v4/VO7hdr75ta+EThyaL5Fre0JqmpVVS2tqqXz5s3rsWxJmnvGEQpnsXXXEcAaYHkbXg5cNdR+djsL6UTg4aHdTJKkMdivz4UnORh4GfBzQ80XAJcnWQHcA5zR2q8GTgPWMzhT6Zw+a5MkbavXUKiqrwCHT2t7gMHZSNP7FnBun/VIkmbnFc2SpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnq9BoKSQ5JckWSzye5PckLkxyW5Jokd7b3Q1vfJLkoyfokNyc5vs/aJEnb6ntL4R3AR6vq2cBzgduB84C1VbUEWNvGAU4FlrTXSuDinmuTJE3TWygkeSbwQ8AlAFX1WFU9BCwDVrduq4HT2/Ay4NIauBY4JMmCvuqTJG2rzy2Fo4EtwHuSfDbJnyU5GJhfVZtan/uA+W14IXDv0PwbWtsTJFmZZF2SdVu2bOmxfEmae/oMhf2A44GLq+p5wFfYuqsIgKoqoHZmoVW1qqqWVtXSefPm7bZiJUn9hsIGYENVXdfGr2AQEvdP7RZq75vb9I3AkUPzL2ptkqQx6S0Uquo+4N4kx7SmU4DbgDXA8ta2HLiqDa8Bzm5nIZ0IPDy0m0mSNAb79bz8XwT+IskBwF3AOQyC6PIkK4B7gDNa36uB04D1wKOtryRpjHoNhaq6CVg6w6RTZuhbwLl91iNJmp1XNEuSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKkzUigkeU7fhUiSJm/ULYV3Jrk+yS+05yRIkvZCI4VCVb0YeB2Du5jekOT9SV7Wa2WSpLEb+ZhCVd0J/CbwFuCHgYvas5d/sq/iJEnjNeoxhe9PciGDZyyfDPx4Vf2XNnxhj/VJksZo1Luk/jHwZ8CvV9VXpxqr6otJfrOXyiRJYzdqKLwC+GpVfQMgyT7AgVX1aFW9r7fqJEljNeoxhb8HDhoaf3prm1WSu5PckuSmJOta22FJrklyZ3s/tLUnyUVJ1ie5OcnxO/tlJElPzqihcGBVfXlqpA0/fcR5X1pVx1XV1MN2zgPWVtUSYG0bBzgVWNJeK4GLR1y+JGk3GTUUvjK85p7k+cBXZ+k/m2XA6ja8Gjh9qP3SGrgWOCTJgl38DEnSLhj1mMIbgA8l+SIQ4NuBnxphvgL+LkkB76qqVcD8qtrUpt8HzG/DC4F7h+bd0No2DbWRZCWDLQmOOuqoEcuXJI1ipFCoqs8keTZwTGu6o6r+c4RZX1RVG5N8G3BNks9PW261wBhZC5ZVAEuXLt2peSVJsxt1SwHgBcDiNs/xSaiqS2eboao2tvfNSa4ETgDuT7Kgqja13UObW/eNDK6YnrKotUmSxmTUi9feB/wB8CIG4fACYOkO5jk4ybdMDQM/CnwOWAMsb92WA1e14TXA2e0spBOBh4d2M0mSxmDULYWlwLFVtTO7a+YDVyaZ+pz3V9VHk3wGuDzJCuAe4IzW/2rgNGA98Chwzk58liRpNxg1FD7H4ODyyGvuVXUX8NwZ2h8ATpmhvYBzR12+JGn3GzUUjgBuS3I98PWpxqp6VS9VSZImYtRQ+J0+i5Ak7RlGPSX1U0m+E1hSVX+f5OnAvv2WJkkat1HPPvpZ4ArgXa1pIfBXfRUlSZqMUW9zcS5wEvAIdA/c+ba+ipIkTcaoofD1qnpsaiTJfgxuYSFJ2ouMGgqfSvLrwEHt2cwfAv66v7IkSZMwaiicB2wBbgF+jsGFZj5xTZL2MqOeffRN4E/bS5K0lxopFJJ8gRmOIVTVd+32iiRJE7Mz9z6aciDwWuCw3V+OJGmSRjqmUFUPDL02VtUfAa/ouTZJ0piNuvvo+KHRfRhsOezMsxgkSU8Bo/5h/8Oh4ceBu9l6y2tJ0l5i1LOPXtp3IZKkyRt199GbZpteVW+fZd59gXXAxqp6ZZKjgcuAw4EbgJ+uqseSPA24FHg+8ADwU1V190jfQpK0W4x68dpS4L8zuBHeQuDngeOBb2mv2fwycPvQ+NuAC6vqWcCDwIrWvgJ4sLVf2PpJksZo1FBYBBxfVW+uqjczWJs/qqreWlVv3d5MSRYxOEvpz9p4gJMZ3HEVYDVwehte1sZp009p/SVJYzJqKMwHHhsaf6y17cgfAb8KfLONHw48VFWPt/ENDLY8aO/3ArTpD7f+kqQxGfXso0uB65Nc2cZPZ+ta/YySvBLYXFU3JHnJrpe4zXJXAisBjjrqqN21WEkSo5999HtJ/hZ4cWs6p6o+u4PZTgJeleQ0BldBfyvwDuCQJPu1rYFFwMbWfyNwJLCh3Zr7mQwOOE+vZRWwCmDp0qXevluSdqNRdx8BPB14pKreweAP99Gzda6qX6uqRVW1GDgT+HhVvQ74BPCa1m05cFUbXtPGadM/XlX+0ZekMRr1cZznA28Bfq017Q/8+S5+5luANyVZz+CYwSWt/RLg8Nb+Jga365YkjdGoxxR+AngecCNAVX0xyY5ORe1U1SeBT7bhu4ATZujzNQY32pMkTciou48ea7tyCiDJwf2VJEmalFFD4fIk72JwkPhngb/HB+5I0l5nh7uP2gVkHwSeDTwCHAP8dlVd03NtkqQx22EoVFUlubqqngMYBJK0Fxt199GNSV7QayWSpIkb9eyjHwD+a5K7ga8AYbAR8f19FSZJGr9ZQyHJUVX1b8CPjakeSdIE7WhL4a8Y3B31niQfrqpXj6MoSdJk7OiYwvCtq7+rz0IkSZO3o1Co7QxLkvZCO9p99NwkjzDYYjioDcPWA83f2mt1kqSxmjUUqmrfcRUiSZq8nbl1tiRpL2coSJI6hoIkqWMoSJI6vYVCkgOTXJ/kn5PcmuStrf3oJNclWZ/kg0kOaO1Pa+Pr2/TFfdUmSZpZn1sKXwdOrqrnAscBL09yIvA24MKqehbwILCi9V8BPNjaL2z9JElj1Fso1MCX2+j+7VXAycAVrX01cHobXtbGadNPac9ykCSNSa/HFJLsm+QmYDODZzH8K/BQVT3eumwAFrbhhcC9AG36w8DhMyxzZZJ1SdZt2bKlz/Ilac7pNRSq6htVdRywCDiBwdPbnuwyV1XV0qpaOm/evCddoyRpq7GcfVRVDwGfAF7I4DnPU1dSLwI2tuGNwJEAbfozgQfGUZ8kaaDPs4/mJTmkDR8EvAy4nUE4vKZ1Ww5c1YbXtHHa9I9XlTfhk6QxGvXJa7tiAbA6yb4MwufyqvqbJLcBlyX5n8BngUta/0uA9yVZD3wJOLPH2iRJM+gtFKrqZuB5M7TfxeD4wvT2rwGv7aseSdKOeUWzJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKnT55PXjkzyiSS3Jbk1yS+39sOSXJPkzvZ+aGtPkouSrE9yc5Lj+6pNkjSzPrcUHgfeXFXHAicC5yY5FjgPWFtVS4C1bRzgVGBJe60ELu6xNknSDHoLharaVFU3tuH/YPB85oXAMmB167YaOL0NLwMurYFrgUOSLOirPknStsZyTCHJYgaP5rwOmF9Vm9qk+4D5bXghcO/QbBta2/RlrUyyLsm6LVu29FazJM1FvYdCkmcAHwbeUFWPDE+rqgJqZ5ZXVauqamlVLZ03b95urFSS1GsoJNmfQSD8RVX9ZWu+f2q3UHvf3No3AkcOzb6otUmSxqTPs48CXALcXlVvH5q0BljehpcDVw21n93OQjoReHhoN5MkaQz263HZJwE/DdyS5KbW9uvABcDlSVYA9wBntGlXA6cB64FHgXN6rE2SNIPeQqGqPg1kO5NPmaF/Aef2VY8kace8olmS1DEUJEkdQ0GS1DEUJEkdQ0GS1DEUJEkdQ0GS1Onz4jVJe7jF531k0iXsVe6+4BWTLuFJc0tBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktTp88lr706yOcnnhtoOS3JNkjvb+6GtPUkuSrI+yc1Jju+rLknS9vW5pfBe4OXT2s4D1lbVEmBtGwc4FVjSXiuBi3usS5K0Hb2FQlX9A/Clac3LgNVteDVw+lD7pTVwLXBIkgV91SZJmtm4jynMr6pNbfg+YH4bXgjcO9RvQ2uTJI3RxA40t2cy187Ol2RlknVJ1m3ZsqWHyiRp7hp3KNw/tVuovW9u7RuBI4f6LWpt26iqVVW1tKqWzps3r9diJWmuGXcorAGWt+HlwFVD7We3s5BOBB4e2s0kSRqT3m6dneQDwEuAI5JsAM4HLgAuT7ICuAc4o3W/GjgNWA88CpzTV12SpO3rLRSq6qztTDplhr4FnNtXLZKk0XhFsySpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjp7VCgkeXmSO5KsT3LepOuRpLlmjwmFJPsC/xc4FTgWOCvJsZOtSpLmlj0mFIATgPVVdVdVPQZcBiybcE2SNKf09ozmXbAQuHdofAPwA9M7JVkJrGyjX05yxxhqmyuOAP590kXsSN426Qo0Af7b3L2+c3sT9qRQGElVrQJWTbqOvVGSdVW1dNJ1SNP5b3N89qTdRxuBI4fGF7U2SdKY7Emh8BlgSZKjkxwAnAmsmXBNkjSn7DG7j6rq8SSvBz4G7Au8u6punXBZc4275bSn8t/mmKSqJl2DJGkPsSftPpIkTZihIEnqGAqSpI6hIGmPleSwJIdNuo65xFCQtEdJclSSy5JsAa4Drk+yubUtnmx1ez9DYY5LMj/J8e01f9L1SMAHgSuBb6+qJVX1LGAB8FcM7ommHnlK6hyV5DjgT4BnsvXK8UXAQ8AvVNWNk6pNc1uSO6tqyc5O0+5hKMxRSW4Cfq6qrpvWfiLwrqp67mQq01yX5DLgS8Bqtt4k80hgOXBEVZ0xqdrmAkNhjtrB2tj6tskujV27zc0KBrfOX9iaNwB/DVxSVV+fVG1zgaEwRyW5CPhu4FKeuDZ2NvCFqnr9pGqTNDmGwhyW5FSeuDa2EVhTVVdPripp+5K8sqr+ZtJ17M0MBUlPGUneWlXnT7qOvZmhoG0kWdkeZiRNRJJnM/NW7O2Tq2pu8DoFzSSTLkBzV5K3MLgeIcD17RXgA0nOm2Rtc4FbCtpGknOq6j2TrkNzU5J/Ab63qv5zWvsBwK1ep9AvtxQ0k7dOugDNad8EvmOG9gVtmnq0xzx5TeOV5ObtTQK83YUm6Q3A2iR3svV06aOAZwGeKt0zdx/NUUnuB34MeHD6JOD/VdVMa2rSWCTZBziBJx5o/kxVfWNyVc0NbinMXX8DPKOqbpo+Icknx1+OtFVVfRO4dtJ1zEVuKUiSOh5oliR1DAVJUsdQ0KySnJ6k2hWmu3O5b0hydhs+LMk1Se5s74fuzs/axfp+J8mvPIn5X5bkhiS3tPeTh6Z9MskdSW5qr2/bwbIOT/KJJF9O8n92taZxS3Jkq/u2JLcm+eWhab+TZOPQb3Baa39OkvdOrGgZCtqhs4BPt/fdIsl+wH8D3t+azgPWtouS1rbxp5T2nYb9O/DjVfUcBs8BeN+06a+rquPaa/MOFv814LeAXQ6pcZjhN3gceHNVHQucCJyb5Nih6RcO/QZXA1TVLcCiJEeNp2pNZyhou5I8A3gRg3vbnznUvk+Sdyb5fFuzvzrJa9q05yf5VFs7/liSBTMs+mTgxqp6vI0vY/BAFdr76buh9ruTHNGGl06dUdXWUN/d1tbvSvJLQ/P8RpJ/SfJp4Jih9u9O8tH2nf5xaqspyXuT/EmS64DfH/78qvpsVX2xjd4KHJTkabvyXarqK1X1aQbhsFskOTDJe9qWzGeTvLS1X5vke4f6fbL9fge33+361n9Zm/4zSdYk+TiDQB+ue9PUE/yq6j+A29l6iuls/pqhf28aL0NBs1kGfLSq/gV4IMnzW/tPAouBY4GfBl4IkGR/4I+B11TV84F3A783w3JPAm4YGp9fVZva8H3McPFckmOGdjVMfx2yk9/r2Qyu0TgBOD/J/u27nQkcB5wGvGCo/yrgF9t3+hXgnUPTFgE/WFVvmuXzXs0gBIcfDvOeVvtvJdkt95pKcuF2fp+ZtrzOBaptyZwFrE5yIIPnI5/RlrcAWFBV64DfAD5eVScALwX+d5KD27KOZ/Df/IdnqW0x8Dxg+El/r09ycwub4V2G64AX7/wvoN3B6xQ0m7OAd7Thy9r4DQy2Hj7UziW/L8knWp9jgO8Drml/5/YFNrGtBQzWGrdRVZVkm/Okq+oOBn+wd4ePtD/QX0+ymUEIvRi4sqoeBUiypr0/A/hB4ENDf7uH1/g/NNsFVW2t+23Ajw41v66qNib5FuDDDIL10if7parqjTvR/UUMApyq+nySe4DvAS4H/g44n0E4XNH6/yjwqqHjLAcyuMoY4Jqq+tL2Pqj9hh8G3lBVj7Tmi4HfBaq9/yGDXYoAm5n5NhcaA0NBM0pyGIPdPM9pf6T3BSrJ/5htNgY3LHvhDhb/VQZ/VKbcn2RBVW1qa6fb7GNPcgyDtdiZvKSqHprW9jhbt4QPnDZteI39G8z+/8E+wENVtb1A+sr2ZkyyCLgSOLuq/nWqvao2tvf/SPJ+BlssTzoUklzIYC1+usuq6oJRltHC6oEk3w/8FPDzU4sHXt3Cefgzf4DZf4P9GQTCX1TVXw59zv1Dff6UwcWUUw5k8G9EE+DuI23Pa4D3VdV3VtXiqjoS+AKDNep/Al7dji3MB17S5rkDmJek2500vH96yO0M7mMzZQ2Dg7G096umz1BVdwwdlJz+mh4IAHcDU7u7Xj3C9/0H4PQkB7U1+B9vn/sI8IUkr23fKUmeu6OFtV1aHwHOq6p/Gmrfb+hYx/7AK4HPtfGfSPK/Rqh1RlX1xu38PjMFwj8Cr2uf+z0M1vqn/uB/EPhV4JlVNXWPrI8Bvzi1qyvJ83ZUT+t7CXB7Vb192rThY00/QfsNmu+ZNq4xMhS0PWcxWMsd9uHW/mEGD1K/Dfhz4Ebg4ap6jEGYvC3JPwM3Mdj1Mt3fAj80NH4B8LIMboD2I238yXor8I4k6xhsDcyqHRD9IPDPrb7PDE1+HbCifadbGRxr2ZHXMwi+384TTz19GvCxDG5IeBODe/r8aZvnu4FHZlpYkruBtwM/k2RDnngWz654J7BPklsYfO+fGTrmcQWD4yuXD/X/XWB/4OYkt7bxHTmJwa6xkzPt1FPg99tB7psZbN0M7/p6KYNA1QR4mwvtkiTPqKovJzmcwUNQTqqq+3Zi/iuBX62qO3sr8ikmyZ8Db6yqLZOuZVLaGVqfAl40dHaaxshQ0C7J4BTPQ4ADgN+vqvfu5PzHMDjr6B92f3V6qkqyBFhYVZ+cdC1zlaEgSep4TEGS1DEUJEkdQ0GS1DEUJEkdQ0GS1Pn/l+KHfkiG79YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50wiFbnvb_xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "a3f695c9-581f-4965-e56c-af4a57e012bb"
      },
      "source": [
        "print(\"Key: \", data_original.metadata['label_maps'])\n",
        "df['credit'].value_counts().plot(kind='bar')\n",
        "plt.xlabel(\"Credit (1 = Good Credit, 2 = Bad Credit)\")\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key:  [{1.0: 'Good Credit', 2.0: 'Bad Credit'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm8RQJL8b_xz"
      },
      "source": [
        "Take a minute to explore the relationship between age category and credit. Is the mean of credit different for young and older people? What does the difference in means indicate?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGiFK1L3b_xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "ac2eed49-2d05-468e-f02e-fb0f57ceb41c"
      },
      "source": [
        "# STUDENT CELL\n",
        "# write code to check the mean credit score by age category\n",
        "dfg = df.groupby(['age'])['credit'].mean()\n",
        "\n",
        "print(dfg)\n",
        "\n",
        "dfg.plot(kind='bar', ylabel='Average Credit (1 = Good Credit, 2 = Bad Credit)',\n",
        "         xlabel='Age (0 = under 25, 1 = over 25)')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age\n",
            "0.0    1.409396\n",
            "1.0    1.280846\n",
            "Name: credit, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f89be2bdbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kITY3AtDb_xz"
      },
      "source": [
        "# Compute Fairness Metrics on Original Training Data\n",
        "Now that we've identified the protected attribute \"age\" and defined privileged and unprivileged values, we can use aif360 to detect bias in the dataset.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZLVzqlmwOXI"
      },
      "source": [
        "## Mean Outcomes\n",
        "\n",
        "Compare the percentage of favorable results for the privileged and unprivileged groups, subtracting the former percentage from the latter. This is equivalent to the mean difference in outcomes by group. A value of 0 indicates parity. A value less than 0 indicates less favorable outcomes for the unprivileged group.  \n",
        "\n",
        "This is implemented in the method called ```mean_difference``` on the BinaryLabelDatasetMetric class.  The code below performs this check and displays the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVQWXC8Ub_x0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359a0c4e-4a9e-468d-a793-c4d9139d7841"
      },
      "source": [
        "metric_train = BinaryLabelDatasetMetric(\n",
        "     data_train, \n",
        "     unprivileged_groups=unprivileged_groups,\n",
        "     privileged_groups=privileged_groups\n",
        "  )\n",
        "print(\"Original training dataset\")\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_train.mean_difference())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training dataset\n",
            "Difference in mean outcomes between unprivileged and privileged groups = -0.169905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZufOXh9b_x0"
      },
      "source": [
        "## Disparate Impact\n",
        "\n",
        "We can calculate the ratio of predicted favorable outcomes for the unprivileged group compared to the privileged group. A value of 1 would indicate no disparate impact. A value less than 1 implies favorable outcomes for the privileged group and a value greater than 1 implies a favorable outcomes for the unprivileged group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iw7g6Hjb_x0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ff67ce-f718-4377-9a89-b7385550df4c"
      },
      "source": [
        "print(\"Original training dataset\")\n",
        "print(\"Disparate Impact = %f\" % metric_train.disparate_impact())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training dataset\n",
            "Disparate Impact = 0.766430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcTiGnSob_x1"
      },
      "source": [
        "## Built-In Explainers\n",
        "\n",
        "```aif360``` has some useful \"explainers\" for the fairness metrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERMXmj2pb_x1"
      },
      "source": [
        "json_expl = MetricJSONExplainer(metric_train)\n",
        "def format_json(json_str):\n",
        "    return json.dumps(json.loads(json_str, object_pairs_hook=OrderedDict),\n",
        "                      indent=2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWuosH5pxVHe"
      },
      "source": [
        "Let's print the mean difference explainer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cc0pIUPxdFl",
        "outputId": "063fbb92-2da6-4661-d42a-5ad0c07268f4"
      },
      "source": [
        "print(format_json(json_expl.mean_difference()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"metric\": \"Mean Difference\",\n",
            "  \"message\": \"Mean difference (mean label value on privileged instances - mean label value on unprivileged instances): -0.1699054740619017\",\n",
            "  \"numPositivesUnprivileged\": 63.0,\n",
            "  \"numInstancesUnprivileged\": 113.0,\n",
            "  \"numPositivesPrivileged\": 427.0,\n",
            "  \"numInstancesPrivileged\": 587.0,\n",
            "  \"description\": \"Computed as the difference of the rate of favorable outcomes received by the unprivileged group to the privileged group.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 0.0\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl-r2vpjxPFo"
      },
      "source": [
        "We can also print the disparate impact explainer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-FoLzMTxSGS",
        "outputId": "2b326ca3-e1e5-4fe4-ad1f-69cb32cb845e"
      },
      "source": [
        "print(format_json(json_expl.disparate_impact()))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"metric\": \"Disparate Impact\",\n",
            "  \"message\": \"Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.7664297113013201\",\n",
            "  \"numPositivePredictionsUnprivileged\": 63.0,\n",
            "  \"numUnprivileged\": 113.0,\n",
            "  \"numPositivePredictionsPrivileged\": 427.0,\n",
            "  \"numPrivileged\": 587.0,\n",
            "  \"description\": \"Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 1.0 A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcDleSrDJr_B"
      },
      "source": [
        "Interpret the difference in means and disparate impact in the German Credit data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HV2t23yJ19P"
      },
      "source": [
        "**Write your interpretation of the difference in means and disparate impact in this text cell**\n",
        "\n",
        "The difference in means indicates a less favorable outcome for the unprivileged group, people under 25. The disparate impact similarly indicates favorable outcomes for the privileged group, people over 25."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riLalr-WwDsG"
      },
      "source": [
        "# Bias Mitigation via In-Processing\n",
        "\n",
        "In-processing methods focus on the model training stage, as compared to pre-processing which focuses on transforming the data prior to model training. Broadly speaking, contemporary in-processing methods are stronger than pre-processing methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUZKKFAo1R1v"
      },
      "source": [
        "## Adversarial Debiasing\n",
        "\n",
        "In this part of the notebook, we'll use an _in-processing_ algorithm called adversarial debiasing to mitigate the bias in credit prediction with respect to age that we observed in the previous section. From the aif360 [documentation](https://aif360.readthedocs.io/en/v0.2.3/modules/inprocessing.html):\n",
        "\n",
        "> Adversarial debiasing is an in-processing technique that learns a classifier to maximize prediction accuracy and simultaneously reduce an adversary’s ability to determine the protected attribute from the predictions. This approach leads to a fair classifier as the predictions cannot carry any group discrimination information that the adversary can exploit.\n",
        "\n",
        "For intuition, you can think of adversarial debiasing as a model with two supervised learning tasks. The first task is to predict an outcome using the training data input. The second task, i.e. the adversary, is to predict a protected feature using these predictions and non-protected features in the training data input. The aim is to maximize the model's ability to carry out the first task (i.e. predict outcomes) while minimizing it's ability to carry out the second task (i.e. predict protected features).\n",
        "\n",
        "We implement adversarial debiasing below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_rWLmHvwBFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd3bbea-0e8c-474f-ab0f-e2dd7ce8e421"
      },
      "source": [
        "# reset tensorflow graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# start tensorflow session\n",
        "sess = tf.Session()\n",
        "\n",
        "# create AdversarialDebiasing model\n",
        "debiased_model = AdversarialDebiasing(\n",
        "    privileged_groups = privileged_groups,\n",
        "    unprivileged_groups = unprivileged_groups,\n",
        "    scope_name = 'debiased_classifier',\n",
        "    debias = True,\n",
        "    sess = sess)\n",
        "\n",
        "# fit the model to training data\n",
        "debiased_model.fit(data_train)\n",
        "\n",
        "# make predictions on training and test data\n",
        "data_debiasing_train = debiased_model.predict(data_train)\n",
        "data_debiasing_test = debiased_model.predict(data_test)\n",
        "\n",
        "# metrics\n",
        "metric_data_debiasing_test = BinaryLabelDatasetMetric(\n",
        "    data_debiasing_test, \n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        "  )\n",
        "\n",
        "# Close session\n",
        "sess.close()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:87: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "epoch 0; iter: 0; batch classifier loss: 88.515305; batch adversarial loss: 0.753964\n",
            "epoch 1; iter: 0; batch classifier loss: 71.864105; batch adversarial loss: 0.705678\n",
            "epoch 2; iter: 0; batch classifier loss: 86.655685; batch adversarial loss: 0.729850\n",
            "epoch 3; iter: 0; batch classifier loss: 59.371357; batch adversarial loss: 0.700880\n",
            "epoch 4; iter: 0; batch classifier loss: 43.893822; batch adversarial loss: 0.703629\n",
            "epoch 5; iter: 0; batch classifier loss: 33.120102; batch adversarial loss: 0.669069\n",
            "epoch 6; iter: 0; batch classifier loss: 42.397316; batch adversarial loss: 0.674632\n",
            "epoch 7; iter: 0; batch classifier loss: 53.969574; batch adversarial loss: 0.710609\n",
            "epoch 8; iter: 0; batch classifier loss: 41.377800; batch adversarial loss: 0.659649\n",
            "epoch 9; iter: 0; batch classifier loss: 29.753386; batch adversarial loss: 0.686812\n",
            "epoch 10; iter: 0; batch classifier loss: 44.795120; batch adversarial loss: 0.688555\n",
            "epoch 11; iter: 0; batch classifier loss: 42.255867; batch adversarial loss: 0.664991\n",
            "epoch 12; iter: 0; batch classifier loss: 30.832874; batch adversarial loss: 0.677924\n",
            "epoch 13; iter: 0; batch classifier loss: 40.818012; batch adversarial loss: 0.645860\n",
            "epoch 14; iter: 0; batch classifier loss: 42.613968; batch adversarial loss: 0.664943\n",
            "epoch 15; iter: 0; batch classifier loss: 38.422745; batch adversarial loss: 0.666830\n",
            "epoch 16; iter: 0; batch classifier loss: 39.936066; batch adversarial loss: 0.662772\n",
            "epoch 17; iter: 0; batch classifier loss: 25.474682; batch adversarial loss: 0.653348\n",
            "epoch 18; iter: 0; batch classifier loss: 20.302973; batch adversarial loss: 0.643039\n",
            "epoch 19; iter: 0; batch classifier loss: 25.672346; batch adversarial loss: 0.630743\n",
            "epoch 20; iter: 0; batch classifier loss: 21.988884; batch adversarial loss: 0.663513\n",
            "epoch 21; iter: 0; batch classifier loss: 30.767685; batch adversarial loss: 0.628364\n",
            "epoch 22; iter: 0; batch classifier loss: 24.173384; batch adversarial loss: 0.645353\n",
            "epoch 23; iter: 0; batch classifier loss: 30.135384; batch adversarial loss: 0.639184\n",
            "epoch 24; iter: 0; batch classifier loss: 25.746296; batch adversarial loss: 0.654058\n",
            "epoch 25; iter: 0; batch classifier loss: 26.873047; batch adversarial loss: 0.653271\n",
            "epoch 26; iter: 0; batch classifier loss: 27.474373; batch adversarial loss: 0.617481\n",
            "epoch 27; iter: 0; batch classifier loss: 24.665260; batch adversarial loss: 0.640966\n",
            "epoch 28; iter: 0; batch classifier loss: 23.359877; batch adversarial loss: 0.635040\n",
            "epoch 29; iter: 0; batch classifier loss: 30.440907; batch adversarial loss: 0.646606\n",
            "epoch 30; iter: 0; batch classifier loss: 18.666498; batch adversarial loss: 0.601968\n",
            "epoch 31; iter: 0; batch classifier loss: 13.449636; batch adversarial loss: 0.610121\n",
            "epoch 32; iter: 0; batch classifier loss: 14.760033; batch adversarial loss: 0.627739\n",
            "epoch 33; iter: 0; batch classifier loss: 18.646538; batch adversarial loss: 0.612537\n",
            "epoch 34; iter: 0; batch classifier loss: 17.645256; batch adversarial loss: 0.575056\n",
            "epoch 35; iter: 0; batch classifier loss: 19.843325; batch adversarial loss: 0.591005\n",
            "epoch 36; iter: 0; batch classifier loss: 34.881184; batch adversarial loss: 0.592157\n",
            "epoch 37; iter: 0; batch classifier loss: 13.422855; batch adversarial loss: 0.636908\n",
            "epoch 38; iter: 0; batch classifier loss: 14.348754; batch adversarial loss: 0.596109\n",
            "epoch 39; iter: 0; batch classifier loss: 14.838099; batch adversarial loss: 0.569023\n",
            "epoch 40; iter: 0; batch classifier loss: 17.225647; batch adversarial loss: 0.581280\n",
            "epoch 41; iter: 0; batch classifier loss: 10.637278; batch adversarial loss: 0.581421\n",
            "epoch 42; iter: 0; batch classifier loss: 11.503899; batch adversarial loss: 0.595790\n",
            "epoch 43; iter: 0; batch classifier loss: 14.665896; batch adversarial loss: 0.628162\n",
            "epoch 44; iter: 0; batch classifier loss: 14.679075; batch adversarial loss: 0.591800\n",
            "epoch 45; iter: 0; batch classifier loss: 12.093798; batch adversarial loss: 0.605142\n",
            "epoch 46; iter: 0; batch classifier loss: 10.191160; batch adversarial loss: 0.535657\n",
            "epoch 47; iter: 0; batch classifier loss: 8.136660; batch adversarial loss: 0.544360\n",
            "epoch 48; iter: 0; batch classifier loss: 10.176826; batch adversarial loss: 0.588431\n",
            "epoch 49; iter: 0; batch classifier loss: 9.639358; batch adversarial loss: 0.540787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWJUD_1-1XOe"
      },
      "source": [
        "## Fairness Metrics under Adversarial Debiasing\n",
        "\n",
        "The adversarial debiasing algorithm has built-in methods for the difference in mean outcomes (called ```.mean_difference()```) and disparate impact (called ```.disparate_impact()```). Print these below: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro-8nuS62NZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "961ea971-51e6-468b-d04b-7957272627dd"
      },
      "source": [
        "# write your code here \n",
        "print(f'Difference in mean outcomes between unprivileged and privileged groups = {metric_data_debiasing_test.mean_difference()}')\n",
        "print(f'Disparate Impact = {metric_data_debiasing_test.disparate_impact()}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = 0.0\n",
            "Disparate Impact = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIQcc23c7SNA"
      },
      "source": [
        "Interpret the difference in means and disparate impact for the predicted outcomes under adversarial debiasing. How do these compare to the metrics calculated on the original data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3MyIpCk7hnp"
      },
      "source": [
        "**Write your interpretation and comparison in this text cell:**\n",
        "\n",
        "The difference in means an disparate impact both indicate no bias. This illustrates how adversarial debiasing effectively removes bias from the original dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Urlnzy3b_x5"
      },
      "source": [
        "# Summary\n",
        "\n",
        "The purpose of this notebook is to introduce some of the functionality of AI Fairness 360 for detecting and mitigating bias. We used an in-processing algorithm called adversarial debiasing. Below, you can run through an implementation of a pre-processing algorithm called reweighing.\n",
        "\n",
        "There are many metrics one can use to detect the presence of bias. Likewise, there are many different bias mitigation algorithms one can employ. AI Fairness 360 provides some of them most common metrics and algorithms. In Lab 4, we will use a different package to further explore bias detection and mitigation.\n",
        "\n",
        "Fairness metrics and mitigation algorithms can be calculated and used in the pre-processing, in-processing, and post-processing stages of the machine learning pipeline. The metrics and algorithms you use will depend, in part, on the particular fairness concerns associated with a machine learning task. We recommend incorporating bias detection in an automated continuous integration pipeline to ensure bias awareness as a project evolves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQIwiWcKb_x3"
      },
      "source": [
        "# Optional: Bias Mitigation via Pre-Processing\n",
        "\n",
        "_Pre-processing_ mitigation happens before the creation of the model.  \n",
        "\n",
        "AI Fairness 360 implements several pre-processing mitigation algorithms.  We will use the **reweighing algorithm**, which is implemented in the `Reweighing` class in the `aif360.algorithms.preprocessing` package. This algorithm will transform the dataset to enhance equity in positive outcomes on the protected attribute for the privileged and unprivileged groups.\n",
        "\n",
        "You can find documentation for reweighting here:\n",
        "https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.preprocessing.Reweighing.html \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOIBqkDSb_x3"
      },
      "source": [
        "## Reweighing\n",
        "\n",
        "Reweighing is a data preprocessing technique that generates weights for the training instances to ensure fairness before classification. The idea is to apply appropriate weights to different tuples in the training data to reduce discrimination with respect to the protected attributes. Instead of reweighing, one could also apply techniques such as suppression, i.e. removing sensitive attributes. However, the reweighing technique is generally more effective.\n",
        "\n",
        "Call the fit and transform methods to perform the transformation, producing a newly transformed training dataset (```dataset_transf_train```):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqBmaYXab_x3"
      },
      "source": [
        "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "                privileged_groups=privileged_groups)\n",
        "data_transf_train = RW.fit_transform(data_train)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdkCX8Fd0zgN"
      },
      "source": [
        "We can print the weights. Each observation in the data should have a weight. For brevity, we'll look at the weights for the first 10 rows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5ISRhOwb_x3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ef7fa5-7930-48c2-973a-d2757d4cc86d"
      },
      "source": [
        "len(data_transf_train.instance_weights)\n",
        "data_transf_train.instance_weights[0:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.678     ])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6wrI5Ab_x4"
      },
      "source": [
        "## Compute Fairness Metrics in Transformed Data\n",
        "\n",
        "Now that we have a transformed dataset, we can check how effective it was in removing bias by calculating the same metrics we used for the original training dataset. As above, we can use the function mean_difference in the BinaryLabelDatasetMetric class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0ubwJbUb_x4"
      },
      "source": [
        "# students will write code here\n",
        "metric_transf_train = BinaryLabelDatasetMetric(\n",
        "    data_transf_train, \n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        "  )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFZh_-La6Eq8"
      },
      "source": [
        "Print the difference in mean outcomes and disparate impact in the transformed data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gim6DapUb_x4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe5972c-6081-469f-ea57-651f7a28ce51"
      },
      "source": [
        "# students will write code here\n",
        "print(\"Transformed training dataset\")\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % metric_transf_train.disparate_impact())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed training dataset\n",
            "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n",
            "Disparate Impact = 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1NdOcvCFmC8"
      },
      "source": [
        "How does this compare to the difference in mean outcomes and disparate impact in the original data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aG_Glh7Frbc"
      },
      "source": [
        "**Write your answer in this text cell:**\n",
        "\n",
        "The difference in means an disparate impact both indicate no bias. This shows how reweighting can also remove bias from the original dataset, but in a pre-processing fashion."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submitting this Lab Notebook\n",
        "\n",
        "Once complete, please submit your lab notebook as an attachment under \"Assignments > Lab 2\" on Brightspace. You can download a copy of your notebook using ```File > Download .ipynb```. Please ensure you submit the `.ipynb` file (and not a `.py` file)."
      ],
      "metadata": {
        "id": "2Zm3d2zXoSeR"
      }
    }
  ]
}